{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fl4OB1lcOSje",
        "outputId": "23ef16cf-e23c-4dc3-fb10-f5edb9907b99",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 179
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "%cd /content/gdrive/My Drive/UCR/Deep Learning/project/\n",
        "!ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n",
            "/content/gdrive/My Drive/UCR/Deep Learning/project\n",
            "adaboost       DenseNet.ipynb  plot1.png  test.obj   validation.obj\n",
            "covid19.model  mdl_wts.hdf5    plot2.png  train.obj\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bWnjd10dOdqC"
      },
      "source": [
        "import pickle\n",
        "dataset_path = \"./\"\n",
        "file = open(dataset_path + 'train.obj','rb')\n",
        "object_file = pickle.load(file)\n",
        "trainX = object_file['images']\n",
        "trainY = object_file['labels']\n",
        "\n",
        "file = open(dataset_path + 'validation.obj','rb')\n",
        "object_file = pickle.load(file)\n",
        "validationX = object_file['images']\n",
        "validationY = object_file['labels']\n",
        "\n",
        "\n",
        "file = open(dataset_path + 'test.obj','rb')\n",
        "object_file = pickle.load(file)\n",
        "testX = object_file['images']\n",
        "testY = object_file['labels']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H8bVkvebjIC6"
      },
      "source": [
        "import numpy as np\n",
        "train_labels = np.where(trainY == 1)[1]\n",
        "train_labels = np.reshape(train_labels, (-1, 1))\n",
        "\n",
        "validation_labels = np.where(validationY == 1)[1]\n",
        "validation_labels = np.reshape(validation_labels, (-1, 1))\n",
        "\n",
        "test_labels = np.where(testY == 1)[1]\n",
        "test_labels = np.reshape(test_labels, (-1, 1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xjy9rGqX-on6",
        "outputId": "7cafb519-92ca-46e0-e80a-14a1dc581159",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "indices = np.where(train_labels == 0)[0]\n",
        "trainX = np.concatenate((trainX, validationX),axis=0)\n",
        "train_labels = np.concatenate((train_labels, validation_labels),axis=0)\n",
        "\n",
        "for i in range(3):\n",
        "    temp = trainX[indices]\n",
        "    trainX = np.concatenate((trainX, temp),axis=0)\n",
        "\n",
        "    temp = train_labels[indices]\n",
        "    train_labels = np.concatenate((train_labels, temp),axis=0)\n",
        "print(trainX.shape, train_labels.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(2748, 224, 224, 3) (2748, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8qbDkmsqOgsd",
        "outputId": "03a63a3d-85b8-404c-85fb-e67dfde43438",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 961
        }
      },
      "source": [
        "!pip install tensorflow-gpu==1.15\n",
        "import tensorflow as tf\n",
        "tf.test.gpu_device_name()\n",
        "from keras import backend as K\n",
        "print(K.tensorflow_backend._get_available_gpus())\n",
        "import keras"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow-gpu==1.15\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a5/ad/933140e74973fb917a194ab814785e7c23680ca5dee6d663a509fe9579b6/tensorflow_gpu-1.15.0-cp36-cp36m-manylinux2010_x86_64.whl (411.5MB)\n",
            "\u001b[K     |████████████████████████████████| 411.5MB 45kB/s \n",
            "\u001b[?25hCollecting gast==0.2.2\n",
            "  Downloading https://files.pythonhosted.org/packages/4e/35/11749bf99b2d4e3cceb4d55ca22590b0d7c2c62b9de38ac4a4a7f4687421/gast-0.2.2.tar.gz\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15) (1.1.0)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15) (0.9.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15) (1.29.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15) (1.1.2)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15) (3.2.1)\n",
            "Collecting tensorflow-estimator==1.15.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/de/62/2ee9cd74c9fa2fa450877847ba560b260f5d0fb70ee0595203082dafcc9d/tensorflow_estimator-1.15.1-py2.py3-none-any.whl (503kB)\n",
            "\u001b[K     |████████████████████████████████| 512kB 36.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15) (0.2.0)\n",
            "Collecting tensorboard<1.16.0,>=1.15.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1e/e9/d3d747a97f7188f48aa5eda486907f3b345cd409f0a0850468ba867db246/tensorboard-1.15.0-py3-none-any.whl (3.8MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8MB 38.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15) (0.34.2)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15) (0.8.1)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15) (1.18.4)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15) (3.10.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15) (1.12.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15) (1.12.1)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15) (1.0.8)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow-gpu==1.15) (1.0.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow-gpu==1.15) (47.1.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow-gpu==1.15) (3.2.2)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow-gpu==1.15) (2.10.0)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow-gpu==1.15) (1.6.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow-gpu==1.15) (3.1.0)\n",
            "Building wheels for collected packages: gast\n",
            "  Building wheel for gast (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gast: filename=gast-0.2.2-cp36-none-any.whl size=7540 sha256=4825b0642ec544ede3d0871c36bbc58741c6801fc0fc0ec8c3ff292fb7ab7f9f\n",
            "  Stored in directory: /root/.cache/pip/wheels/5c/2e/7e/a1d4d4fcebe6c381f378ce7743a3ced3699feb89bcfbdadadd\n",
            "Successfully built gast\n",
            "\u001b[31mERROR: tensorflow 2.2.0 has requirement gast==0.3.3, but you'll have gast 0.2.2 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensorflow 2.2.0 has requirement tensorboard<2.3.0,>=2.2.0, but you'll have tensorboard 1.15.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensorflow 2.2.0 has requirement tensorflow-estimator<2.3.0,>=2.2.0, but you'll have tensorflow-estimator 1.15.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensorflow-probability 0.10.0 has requirement gast>=0.3.2, but you'll have gast 0.2.2 which is incompatible.\u001b[0m\n",
            "Installing collected packages: gast, tensorflow-estimator, tensorboard, tensorflow-gpu\n",
            "  Found existing installation: gast 0.3.3\n",
            "    Uninstalling gast-0.3.3:\n",
            "      Successfully uninstalled gast-0.3.3\n",
            "  Found existing installation: tensorflow-estimator 2.2.0\n",
            "    Uninstalling tensorflow-estimator-2.2.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.2.0\n",
            "  Found existing installation: tensorboard 2.2.2\n",
            "    Uninstalling tensorboard-2.2.2:\n",
            "      Successfully uninstalled tensorboard-2.2.2\n",
            "Successfully installed gast-0.2.2 tensorboard-1.15.0 tensorflow-estimator-1.15.1 tensorflow-gpu-1.15.0\n",
            "['/job:localhost/replica:0/task:0/device:GPU:0']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V-wQ6v4pOvg3",
        "outputId": "f2ac69f2-adac-4192-b343-621b9fd37c7f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 890
        }
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "base = './adaboost/'\n",
        "end = '/covid19.model'\n",
        "model_paths = ['VGG', 'ResNet50', 'DenseNet']\n",
        "for j in range(len(model_paths)):\n",
        "    path = base+model_paths[j]+end\n",
        "    tf.keras.backend.clear_session()\n",
        "    model = tf.keras.models.load_model(path)\n",
        "    input_layers = []\n",
        "    for i in range(len(model.layers)-2):\n",
        "        input_layers.append(model.layers[i])\n",
        "    feature_extractor = Model(inputs=model.inputs, outputs=model.layers[-2].output)\n",
        "\n",
        "    output = feature_extractor.predict(trainX, batch_size=16)\n",
        "    if j == 0:\n",
        "        train_features = output\n",
        "    else:\n",
        "        train_features = np.concatenate((train_features, output),axis=1)\n",
        "\n",
        "    output = feature_extractor.predict(testX, batch_size=16)\n",
        "    if j == 0:\n",
        "        test_features = output\n",
        "    else:\n",
        "        test_features = np.concatenate((test_features, output),axis=1)\n",
        "    print(test_features.shape, type(test_features))\n",
        "\n",
        "    categories = ['covid', 'normal', 'ph']\n",
        "    print(\"[INFO] evaluating network...\")\n",
        "    predIdxs = model.predict(testX, batch_size=16)\n",
        "    predIdxs = np.argmax(predIdxs, axis=1)\n",
        "    print(classification_report(testY.argmax(axis=1), predIdxs, target_names=categories))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/init_ops.py:97: calling GlorotUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/init_ops.py:97: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "(580, 512) <class 'numpy.ndarray'>\n",
            "[INFO] evaluating network...\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       covid       0.91      0.95      0.93        43\n",
            "      normal       0.91      0.97      0.94       268\n",
            "          ph       0.96      0.90      0.93       269\n",
            "\n",
            "    accuracy                           0.93       580\n",
            "   macro avg       0.93      0.94      0.93       580\n",
            "weighted avg       0.94      0.93      0.93       580\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/init_ops.py:97: calling Ones.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "(580, 2560) <class 'numpy.ndarray'>\n",
            "[INFO] evaluating network...\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       covid       0.11      1.00      0.20        43\n",
            "      normal       0.99      0.49      0.66       268\n",
            "          ph       0.68      0.17      0.27       269\n",
            "\n",
            "    accuracy                           0.38       580\n",
            "   macro avg       0.59      0.55      0.38       580\n",
            "weighted avg       0.78      0.38      0.44       580\n",
            "\n",
            "(580, 96640) <class 'numpy.ndarray'>\n",
            "[INFO] evaluating network...\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       covid       0.89      0.95      0.92        43\n",
            "      normal       0.92      0.98      0.95       268\n",
            "          ph       0.98      0.90      0.94       269\n",
            "\n",
            "    accuracy                           0.94       580\n",
            "   macro avg       0.93      0.94      0.94       580\n",
            "weighted avg       0.94      0.94      0.94       580\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JhKMcIKN66RH",
        "outputId": "701d98a1-40ff-4bb5-e25d-5578e9d8c47e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "print(train_features.shape, type(train_features))\n",
        "print(train_labels.shape, type(train_labels))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(2748, 96640) <class 'numpy.ndarray'>\n",
            "(2748, 1) <class 'numpy.ndarray'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6lut602P7HdE"
      },
      "source": [
        "X = train_features[:,0:6000]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y9V-viJ74yMk",
        "outputId": "7eafe925-1c94-4adc-f280-0b613043a89c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        }
      },
      "source": [
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "clf = AdaBoostClassifier(n_estimators=150, random_state=0)\n",
        "clf.fit(X, train_labels)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None, learning_rate=1.0,\n",
              "                   n_estimators=300, random_state=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lS0aem6R7sFZ"
      },
      "source": [
        "predictions = clf.predict(test_features[:,0:6000])\n",
        "predictions = np.reshape(predictions, (-1, 1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1uT_Ir4w9Qyc",
        "outputId": "2a315e8b-1b3d-487a-e4c6-8105d092f2a0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "print(predictions.shape)\n",
        "print(test_labels.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(580, 1)\n",
            "(580, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "haCnVyRe9nFN",
        "outputId": "30a45ccc-7051-4ae5-fb04-f62a9caeb485",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "from sklearn.metrics import accuracy_score,  confusion_matrix\n",
        "print(accuracy_score(test_labels, predictions))\n",
        "print(confusion_matrix(test_labels, predictions))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9568965517241379\n",
            "[[ 41   0   2]\n",
            " [  0 258  10]\n",
            " [  0  13 256]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jhQSZWghBEWF"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DYa9o2ha6j_d"
      },
      "source": [
        "clf = AdaBoostClassifier(n_estimators=100, random_state=0)\n",
        "clf.fit(train_features, train_labels)\n",
        "predictions = clf.predict(test_features)\n",
        "predictions = np.reshape(predictions, (-1, 1))\n",
        "print(accuracy_score(test_labels, predictions))\n",
        "print(confusion_matrix(test_labels, predictions))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}